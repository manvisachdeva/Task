# Speech Synthesis with VITS: AI4Bharat Corpus (Non-Hindi Language)
This project focuses on developing a robust speech synthesis model using the VITS (Variational Inference Text-to-Speech) architecture. The model will be trained on a non-Hindi language from the AI4Bharat data corpus to generate high-quality, natural-sounding audio from text input. The goal is to leverage advanced machine learning techniques to achieve state-of-the-art results in text-to-speech (TTS) synthesis, while specifically excluding news datasets.

Additionally, the model will be designed to support streaming audio conversion. The synthesized speech will be streamed from WAV to FLAC format using WebSockets, ensuring efficient and high-quality audio transmission.
